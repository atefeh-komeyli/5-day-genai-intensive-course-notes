## ğŸ§  DAY 1 â€“ Deep Dive into Large Language Models (LLMs) 

---

**Google AI Course - Companion Summary**  
ğŸ”— [Watch the Podcast â€“ Part 1](https://www.youtube.com/watch?v=mQDlCZZsOyo&list=PLqFaTIg4myu8GFXsSEicf6q_ExhfOr5ck)  
ğŸ”— [Watch the Podcast â€“ Part 2](https://www.youtube.com/watch?v=F_hJ2Ey4BNc&list=PLqFaTIg4myu8GFXsSEicf6q_ExhfOr5ck&index=2)

---

### ğŸ”§ Training Process

Large Language Models go through a 3-stage development cycle:

- **Pre-training**  
  Learn general language patterns from massive unlabeled datasets.

- **Fine-tuning**  
  Adapt the model for specific tasks using smaller labeled datasets.

- **RLHF (Reinforcement Learning from Human Feedback)**  
  Models learn from human preferences via a reward model to align better with human expectations.

â¡ï¸ **Parameter-Efficient Fine-Tuning (PEFT)** techniques help reduce training costs:
- **Adapters** â€“ Lightweight modules inserted into model layers.
- **LoRA / QLoRA** â€“ Low-Rank Adaptation for minimal parameter updates.
- **Soft Prompting** â€“ Trainable input embeddings without altering model weights.

---

### âœï¸ Prompt Engineering Techniques

Prompting is key to getting smart outputs from LLMs. Strategies include:

- **Zero-shot** â€“ Ask directly, no examples.
- **Few-shot / One-shot** â€“ Provide a few guiding examples.
- **Chain-of-Thought (CoT)** â€“ Encourage step-by-step reasoning.
- **Self-consistency** â€“ Sample multiple reasoning paths and choose the best.
- **Tree of Thoughts (ToT)** â€“ Parallel reasoning branches.
- **ReAct** â€“ Mix reasoning and actions (e.g., calling tools).
- **System Prompting** â€“ Set the model's behavior or role.
- **Role Prompting** â€“ Define a persona for style/tone control.
- **Contextual Prompting** â€“ Add background or documents for relevance.
- **Step-back Prompting** â€“ Zoom out to reframe questions.
- **APE (Auto Prompt Engineering)** â€“ Let the model iterate and pick effective prompts.

---

### âš™ï¸ Sampling & Generation Methods

Controls how the model generates text:

- **Temperature** â€“ Lower = focused & deterministic; higher = diverse & creative.
- **Top-K Sampling** â€“ Pick from top K likely tokens.
- **Top-P (Nucleus)** â€“ Sample from smallest token set with cumulative probability over a threshold.
- **Greedy Search** â€“ Always pick the most probable token (risk: repetitive output).
- **Random Sampling** â€“ More diverse but less coherent.
- **Best-of-n** â€“ Generate several completions and select the best.

---

### ğŸ“ˆ Evolution of Language Models

| Model         | Highlights |
|---------------|------------|
| **GPT-1**      | Intro to generative pre-training + fine-tuning |
| **BERT**       | Encoder-only; excels at classification |
| **GPT-2**      | Strong zero-shot capabilities |
| **GPT-3**      | 175B params; great at few-shot tasks |
| **InstructGPT**| GPT-3 + human feedback for instructions |
| **GPT-3.5/4**  | Improved reasoning, multi-modal support |
| **LaMDA**      | Dialogue-focused by Google |
| **Gopher**     | DeepMindâ€™s large model |
| **PaLM / PaLM 2** | Great for code & reasoning |
| **Gemini**     | Multi-modal, TPU-optimized (Google) |
| **Gemma**      | Lightweight, open-source |
| **LLaMA 3**     | Metaâ€™s powerful open-source family |
| **Mistral**     | Compact and high-performance |
| **O1 Models**   | Transparent and tunable |
| **DeepSeek**    | RL innovations (Group Relative Policy) |

---

### âš¡ Inference Optimization Techniques

Speed up and scale model inference with these tools:

- **Quantization** â€“ Use lower-precision weights to save memory.
- **QAT (Quantization-Aware Training)** â€“ Train with quantization in mind.
- **Distillation** â€“ Smaller models learn from larger ones.
- **Flash Attention** â€“ Faster and more efficient attention computation.
- **Prefix Caching** â€“ Avoid recomputing previous tokens.
- **Speculative Decoding** â€“ Use a smaller model to guess tokens, then validate with a larger model.

---

### ğŸ“ Evaluation Strategies

LLMs are evaluated using a mix of automatic and human methods:

- **Accuracy** â€“ Factual correctness.
- **Helpfulness** â€“ Relevance to user intent.
- **Creativity** â€“ Novel and thoughtful responses.
- **BLEU / ROUGE** â€“ Standard metrics for text generation.
- **Human Feedback** â€“ Manual scoring of responses.
- **LLM-as-a-Judge** â€“ Use another LLM to rate outputs.

---

### ğŸ› ï¸ LLM Applications

- âœ… Code generation & explanation  
- ğŸŒ Translation & localization  
- ğŸ“ Summarization  
- ğŸ¤– Chatbots & virtual agents  
- ğŸ§¾ Text classification (e.g., spam, sentiment)  
- ğŸ” Information retrieval & RAG systems  
- ğŸ¨ Multimodal AI (text + image/audio/video)

---

### âœ… Best Practices

- Write **clear, focused prompts**
- Use **few-shot examples** for guidance
- **Structure output** with formats like JSON or CSV
- Adjust **temperature & sampling** for tone control
- **Log and analyze** prompt-output pairs
- Use **validators** to check structured outputs
- Add **reasoning steps** for complex answers (e.g., CoT)
- Keep iterating and document learnings!

---
